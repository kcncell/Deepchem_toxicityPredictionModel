{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f505ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Deepchem is a fantastic package to explore deeplearning in chemistry and biological science.\n",
    "#It has been a great learning curuve, especially coming from keras, but everything is very well documented.\n",
    "#This is just my effort to practice more and get myself more aquainted witht the concept and package.\n",
    "#I hope this document will help many others who wants to learn DeepLearning in chemistry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebab5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am assuming you have installed the \"Deepchem\" and \"rdkit\" packages.\n",
    "#let's import both of them\n",
    "import deepchem as dc\n",
    "import rdkit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b143b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:30:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:30:37] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [15:31:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:31:00] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "#deepchem has the 'molnet' module that has built in function to pull lots of scientific data, most of them are already sorted.\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(reload =False)\n",
    "\n",
    "#let's import toxicity dataset. You can check the three outputs individually.\n",
    "#make sure the reload parameter set to 'False', if your code doesn't work. I struggled with this for hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263c6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n"
     ]
    }
   ],
   "source": [
    "print(tasks) #task represent the response of each compounds to the 12 assays, basically 12 outcomes for 12 assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe80d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets has all the data, let's split them into the groups of three: train, vaid, test\n",
    "train_data, valid_data, test_data = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54fcedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6264, 1024) (6264, 12) (6264, 12)\n",
      "(783, 1024) (783, 12) (783, 12)\n",
      "(784, 1024) (784, 12) (784, 12)\n"
     ]
    }
   ],
   "source": [
    "#you can check the shape of each type of data, it is important to know the shape before the model.\n",
    "#each set has three variables, X: the molecules, y:assay the outcome, and w:the weight for certain assays are set to zero if there are no data available,\n",
    "print(train_data.X.shape, train_data.y.shape, train_data.w.shape)\n",
    "print(valid_data.X.shape, valid_data.y.shape, valid_data.w.shape)\n",
    "print(test_data.X.shape, test_data.y.shape, test_data.w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4247b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have 6264 compounds in the training sample, and 783 and 784 compounds for validation set and the test set.\n",
    "#1024 is the dimension of the vector, this vector was created after featuring every molecule.\n",
    "#we have used the deafult featurization: ECFP(extended connectivity finger printing)\n",
    "#ECFP converts each molecule into a fixed dimension(1024) vector, which will be used as input in the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ed1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<deepchem.trans.transformers.BalancingTransformer object at 0x7f7f2dbe2290>]\n"
     ]
    }
   ],
   "source": [
    "#the last thing the load function output is the type of transformers it has used.\n",
    "#this function has used Balancingtransformers, you can find the type by printing it out.\n",
    "#this transformer balance the uneven datasets\n",
    "print(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6409ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 15:56:14.474775: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-30 15:56:14.477354: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# now let's create a model\n",
    "\n",
    "model = dc.models.MultitaskClassifier(n_tasks=train_data.y.shape[1],   #equals to 12 assays data  \n",
    "                                     n_features=train_data.X.shape[1], #equals to 1024 features                                    \n",
    "                                     layer_sizes=[500],                #we will have one hidden layers with 500 arbitary neurons, you have to play around\n",
    "                                     dropouts=0.5)                     # we will drop 50 percent of the neurons randomly,\n",
    "                                                                       #this model already uses relu activation function by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28199d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15401579856872558"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the easy part, fitting the model into your trainning dataset.\n",
    "\n",
    "model.fit(train_data, nb_epoch=50)\n",
    "\n",
    "#i have chosen arbitarily 50 epochs, one epoch means the entired data has been cycled through 50 times through the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047b6c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9905262531017529}\n",
      "{'mean-roc_auc_score': 0.6713550605074426}\n"
     ]
    }
   ],
   "source": [
    "#now we will evaluate our model on the test sample. But before that we have to choose the proper metrics method.\n",
    "#good thing about the deepchem is that it has dc.metrics.Metric module that wrap the common metric method and-\n",
    "#-that is extremely helpful to find the metrics for training and testing datasets anyway you would like.\n",
    "\n",
    "met = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "\n",
    "train_score = model.evaluate(train_data, [met], transformers)\n",
    "test_score = model.evaluate(test_data, [met], transformers)\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we definitely overfitted the model\n",
    "#if you would want to find the toxicity of any molecule here are the few things you would have to do.\n",
    "# 1. get the SMILE notation of the molecule\n",
    "# 2. convert it into a mol obeject by using rdkit\n",
    "# 3. featurize the mol object by using the deepchem's ECFP featurizer. it should be an array of (,1024) features,\n",
    "# 4. then use the predict function to predict.\n",
    "# I will explore more on the different datasets in the future projects.\n",
    "# This is a reacreation of the toxicity project from the book \"Deep learning for the life sciences\". I will highly recommend reading it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
